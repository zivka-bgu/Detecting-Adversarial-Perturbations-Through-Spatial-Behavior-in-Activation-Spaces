{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks import CarliniWagnerL2\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "import tensorflow as tf\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "import matplotlib\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import os.path\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Construct a simple CNN classifeir for the MNIST dataset\n",
    "'''\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get the activation outputs from each of the model's layers given some input\n",
    "'''\n",
    "def get_activations(model, model_inputs, print_shape_only=True, layer_name=None):\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.get_input_at(0)\n",
    "\n",
    "    model_multi_inputs_cond = True\n",
    "    if not isinstance(inp, list):\n",
    "        # only one input! let's wrap it in a list.\n",
    "        inp = [inp]\n",
    "        model_multi_inputs_cond = False\n",
    "\n",
    "    outputs = [layer.output for layer in model.layers if (layer.__class__.__name__ == 'Conv2D' or layer.__class__.__name__ == 'Dense' or layer.__class__.__name__ == 'MaxPooling2D') and\n",
    "               (layer.name == layer_name or layer_name is None)]  # all layer outputs\n",
    "\n",
    "    # Define a Keras function for evaluating each of the relevant layer outputs\n",
    "    # We use the global model input tensor, combined with the per-layer output in order to deinfe the function\n",
    "    funcs = [K.function(inp, [out]) for out in outputs]  # evaluation functions\n",
    "\n",
    "    # Prepare the input tensors for evaluation\n",
    "    if model_multi_inputs_cond:\n",
    "        list_inputs = []\n",
    "        list_inputs.extend(model_inputs)\n",
    "        list_inputs.append(0.)\n",
    "    else:\n",
    "        list_inputs = [model_inputs, 0.]\n",
    "\n",
    "    # Execute each of the layers and collect the outputs\n",
    "    for func in funcs:\n",
    "        layer_activations = func(list_inputs)[0]\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' A simple wrapper function for generating adversarial examples baesd on the CleverHans library\n",
    "'''\n",
    "def GenerateAdvExamples(model, sess, filtered, target, attack_type = 'CW', batch_size=1000, wrap=None, params=None):\n",
    "    if wrap == None:\n",
    "        print('Creating a KerasModelWrapper')\n",
    "        wrap = KerasModelWrapper(model)\n",
    "    \n",
    "    if attack_type == 'CW':\n",
    "        if params == None:\n",
    "            params = {#'batch_size':50,\n",
    "                      #'ord':1,\n",
    "                      'learning_rate':0.01,\n",
    "                      'binary_search_steps':9,\n",
    "                      'initial_const':0.001,\n",
    "                      'max_iterations':1000,\n",
    "                      'confidence':5,\n",
    "                      'clip_min':0,\n",
    "                      'clip_max':1\n",
    "                      }\n",
    "        attack = CarliniWagnerL2(wrap, sess=sess)  \n",
    "    elif attack_type == 'FGSM':\n",
    "        if params == None:\n",
    "            params = {'eps': 0.3}\n",
    "        attack = FastGradientMethod(wrap, sess=sess)\n",
    "    elif attack_type == 'BIM':\n",
    "        attack = BasicIterativeMethod(wrap, sess=sess)\n",
    "        if params == None:\n",
    "            params = {'eps': 0.3,\n",
    "                      'eps_iter':0.05,\n",
    "                      'clip_min': 0.,\n",
    "                      'clip_max': 1.\n",
    "                      }\n",
    "    elif attack_type == 'JSMA':\n",
    "        attack = SaliencyMapMethod(wrap, sess=sess)\n",
    "        if params == None:\n",
    "            params = {'theta': 1., \n",
    "                      'gamma': 0.1,\n",
    "                      'clip_min': 0., \n",
    "                      'clip_max': 1.\n",
    "                      }\n",
    "            \n",
    "    # Calculate the adversarial examples in chunks in order to prevent GPU out of memory exceptions\n",
    "    adv_x = np.empty(filtered.shape)\n",
    "    for offset in range(math.ceil(len(filtered) / batch_size)):\n",
    "        start_offset = offset*batch_size\n",
    "        end_offset = (offset+1)*batch_size\n",
    "        if (end_offset > len(filtered)):\n",
    "            end_offset = len(filtered)\n",
    "        if target is not None:\n",
    "            params['y_target'] = target[start_offset:end_offset]\n",
    "        print('Calculating adversarial examples using ', attack_type, ' offset:', start_offset, ':', end_offset)\n",
    "        #print(params)\n",
    "        adv_x[start_offset:end_offset] = attack.generate_np(filtered[start_offset:end_offset], **params)\n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate the PCA transform per each of the model's layer outputs\n",
    "'''\n",
    "def pca_project_activations(activation_maps, components = 1000):\n",
    "    pca_projections = []\n",
    "    act_vectors = []\n",
    "    \n",
    "    for i, activation_map in enumerate(activation_maps):\n",
    "        temp = []\n",
    "        print('Projecting layer {}'.format(i))\n",
    "        for instance in activation_map:\n",
    "            temp.append(instance.flatten())\n",
    "\n",
    "        dim = components\n",
    "        if len(temp[0]) < components:\n",
    "            print('Layer: ', i, 'Maintaining dimensionality')\n",
    "            dim = len(temp[0])\n",
    "        else:\n",
    "            print('Layer: ', i, 'Reducing dimensionality')\n",
    "            \n",
    "        pca = PCA(n_components = dim)\n",
    "        temp = pca.fit_transform(np.asarray(temp))\n",
    "        act_vectors.append(np.asarray(temp))\n",
    "        pca_projections.append(pca)\n",
    "       \n",
    "    return pca_projections, act_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot the log lie'''\n",
    "def plot_log_likelihood(tags, adv_tags, test_samples, adv_samples, start_layer = 0):\n",
    "    # Per instance classification switches between layers\n",
    "    switch_map = np.not_equal(tags[:, :-1], tags[:, 1:])\n",
    "    adv_switch_map = np.not_equal(adv_tags[:, :-1], adv_tags[:, 1:])\n",
    "    \n",
    "    # a-priori switch probability per layer (normal / adv)\n",
    "    bias = -0.3\n",
    "    switch_prob = np.sum(switch_map, axis=0)/test_samples\n",
    "    adv_switch_prob = np.sum(adv_switch_map, axis=0)/adv_samples\n",
    "    \n",
    "    # Calculate the number of class switches in the last 1/3\n",
    "    start = len(switch_prob) // 3 * 2\n",
    "\n",
    "    # Boosting penalty factor\n",
    "    factor = 5\n",
    "    \n",
    "    # Calculate agreements on the last third\n",
    "    agreements = np.zeros(test_samples)\n",
    "    for i in range(test_samples):\n",
    "        agreements[i] = len(np.where(tags[i, start:] == tags[i][len(switch_prob)])[0])\n",
    "    agreement_prob, bins = np.histogram(agreements, bins=len(switch_prob) - start + 1)\n",
    "    total = sum(agreement_prob)\n",
    "    agreement_prob = agreement_prob / total\n",
    "    agreement_log_prob = np.log(agreement_prob) * factor\n",
    "    adv_agreements = np.zeros(adv_samples)\n",
    "    for i in range(adv_samples):\n",
    "        adv_agreements[i] = int(len(np.where(adv_tags[i, start:] == adv_tags[i][len(switch_prob)])[0]))\n",
    "        \n",
    "    if start_layer > 0:\n",
    "        switch_prob[0:start_layer] = 0.5\n",
    "\n",
    "    \n",
    "    # Normal samples likelihood calculation\n",
    "    probs = switch_map * np.array([switch_prob,]*test_samples)\n",
    "    mask = [probs == 0]\n",
    "    probs[mask] = 1 - np.array([switch_prob,]*test_samples)[mask]\n",
    "    log_probs = np.log(probs)\n",
    "    probs = np.prod(probs, axis=1)\n",
    "    log_probs = np.sum(log_probs, axis=1)\n",
    "    log_probs += agreement_log_prob[agreements.astype(int) -1]\n",
    "    \n",
    "    # Adversarial samples likelihood calculation\n",
    "    adv_probs = adv_switch_map * np.array([switch_prob,]*adv_samples)\n",
    "    mask = [adv_probs == 0]\n",
    "    adv_probs[mask] = 1- np.array([switch_prob,]*adv_samples)[mask]\n",
    "    adv_log_probs = np.log(adv_probs)\n",
    "    adv_probs = np.prod(adv_probs, axis=1)\n",
    "    adv_log_probs = np.sum(adv_log_probs, axis=1)\n",
    "    adv_log_probs += agreement_log_prob[adv_agreements.astype(int) -1]\n",
    "    \n",
    "    # Plotting\n",
    "    from scipy.stats import binned_statistic\n",
    "    percentiles = [np.percentile(log_probs, q) for q in np.arange(0, 100, 5)]\n",
    "    #print(percentiles)\n",
    "    adv_percentiles = [np.percentile(adv_log_probs, q) for q in np.arange(0, 100, 5)]\n",
    "    plt.figure(dpi=600, figsize= (6,4))\n",
    "    plt.plot(np.arange(0, 1, 0.05), percentiles, '-o', c='blue', label='normal')\n",
    "    plt.plot(np.arange(0, 1, 0.05), adv_percentiles, '-o', c='red',  label='adv')\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.ylabel('Log likelihood')\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    return switch_prob, adv_switch_prob, log_probs, adv_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_apriori_switch_prob(switch_prob, adv_switch_prob):\n",
    "    \n",
    "    plt.figure(dpi=600, figsize=(6,4))\n",
    "    plt.plot(switch_prob, '-o', label='normal', c='blue')\n",
    "    plt.plot(adv_switch_prob, '-o', label='adv', c='red')\n",
    "    layer_count = len(switch_prob)\n",
    "    tick = layer_count // 10\n",
    "    if tick == 0:\n",
    "        tick += 1\n",
    "    #plt.xticks(np.arange(0, layer_count, tick), np.arange(2, layer_count + 2, tick))\n",
    "    plt.xticks(np.arange(0, layer_count, tick),[])\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.legend(loc=2)\n",
    "    plt.axes().yaxis.grid(True)\n",
    "    #plt.title('a-priori classification switch probability')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcMeanPerturbationDistance(orig, adv, metric=2):\n",
    "    dist = 0\n",
    "    avg_dist = 0\n",
    "    for index in range(len(adv)):\n",
    "        if metric == 0:\n",
    "            # Count all perturbed pixels\n",
    "            dist = (adv[index] != orig[index])\n",
    "            dist = np.sum(dist)\n",
    "        elif metric == 2:\n",
    "            # Euclidian pixel value distance\n",
    "            dist = (adv[index] - orig[index])**2\n",
    "            dist = np.sum(dist)\n",
    "            dist = math.sqrt(dist)\n",
    "        elif metric == np.inf:\n",
    "            # Max change to any pixel\n",
    "            dist = np.abs(adv[index] - orig[index])\n",
    "            dist = np.max(dist)\n",
    "        \n",
    "        avg_dist += dist\n",
    "    avg_dist /= len(adv)\n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_manifold_tsne(act_vectors):\n",
    "    # Calculate PCA, then t-SNE for each of the layers than plot by class label\n",
    "    tsne = TSNE(n_components=2, n_jobs=8)\n",
    "    tsne_outputs = []\n",
    "       \n",
    "    for i in range(len(act_vectors)):\n",
    "        print('Projecting tSNE for layer {}'.format(i))\n",
    "        \n",
    "        pca_result = act_vectors[i]\n",
    "        #pca_result = pca.fit_transform(act_vectors)\n",
    "        tsne_result = tsne.fit_transform(pca_result)\n",
    "        tsne_outputs.append(tsne_result)\n",
    "        \n",
    "    return tsne_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "'''\n",
    "\n",
    "# Create TF session and set as Keras backend session\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(x_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 5000\n",
    "adv_samples = 5000\n",
    "a = get_activations(model, x_test[0:test_samples], print_shape_only=True)  # with 200 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_val = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = x_test[test_samples:test_samples + adv_samples]\n",
    "source = y_test[test_samples:test_samples + adv_samples]\n",
    "target = (y_test_val[test_samples:test_samples + adv_samples] + np.random.randint(1, num_classes, size=(adv_samples))) % num_classes\n",
    "target = keras.utils.to_categorical(target, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x = GenerateAdvExamples(model, sess, filtered, target=target, attack_type='FGSM')\n",
    "preds_fgsm = model.predict(adv_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(adv_x, source, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Successfully moved out of source class:', 1 - score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(adv_x, target, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Successfully perturbed to target class:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average perturbation distance\n",
    "avg_dist = CalcMeanPerturbationDistance(filtered, adv_x)\n",
    "print('Average distance for adv input: %.2f'%avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the activation values\n",
    "a_adv = get_activations(model, adv_x, print_shape_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Euclidian spaces using PCA, and project the normal input activation maps\n",
    "(pca_projections, act_vectors) = pca_project_activations(a, components = 100)\n",
    "a = None # Free up some memory by dropping the raw activaiton values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot TSNE projections of the normal examples\n",
    "tsne_oputputs = activation_manifold_tsne(act_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_width = 8\n",
    "plot_height = 200\n",
    "labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Adv']\n",
    "colors = ['red', 'green', 'blue', 'yellow', 'pink', 'orange', 'brown', 'purple', 'grey', 'black']\n",
    "classes = np.asarray(y_test_val[0:test_samples])\n",
    "\n",
    "for layer in range(len(tsne_oputputs)):\n",
    "        print('Displaying activation map {}'.format(layer))\n",
    "        \n",
    "        s = [100 for n in range(len(classes))]\n",
    "        \n",
    "        for count in range(11):\n",
    "            if (count != 10):\n",
    "                plt.scatter(x=tsne_oputputs[layer][classes == count, 0], y=tsne_oputputs[layer][classes == count, 1], c= colors[count], s=s, marker='o', label=str(count), alpha=0.5)\n",
    "            else:\n",
    "                #ax[i].scatter(x=tsne_result[classes == count, 0], y=tsne_result[classes == count, 1], c='black', s=s, marker='+', label='Adv', alpha=0.5)\n",
    "                break\n",
    "        lgd = plt.legend(loc=2)\n",
    "        #plt.axis('off')\n",
    "        #plt.xticks(np.arange(10))\n",
    "        #ax[i].text(x=0.5, y=0.9, s='Layer Activation - '+str(i), transform=ax[i].transAxes, size='large', horizontalalignment='center')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the adversarial activaitons using the calculated PCA spaces\n",
    "adv_act_vectors = []\n",
    "for i, activation_map in enumerate(a_adv):\n",
    "    print('Projecting adversarial activations for layer: ', i)\n",
    "    temp = []\n",
    "    for instance in activation_map:\n",
    "        temp.append(instance.flatten())\n",
    "    \n",
    "    temp = pca_projections[i].transform(np.asarray(temp))\n",
    "    adv_act_vectors.append(np.asarray(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a kNN classifier per each layer output\n",
    "classifiers = []\n",
    "for i in range(len(act_vectors)):\n",
    "    print('Fitting kNN classifer for layer - ', str(i))\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "    classifier.fit(act_vectors[i][0:test_samples], y_test_val[0:test_samples])\n",
    "    classifiers.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = np.zeros([test_samples, len(classifiers)])\n",
    "adv_tags = np.zeros([adv_samples, len(classifiers)])\n",
    "\n",
    "for index in range(test_samples):\n",
    "    clear_output(wait=True)\n",
    "    print('Calculating classifications: ', index)\n",
    "    for layer in range(len(classifiers)):\n",
    "        tags[index, layer] = classifiers[layer].predict(act_vectors[layer][index].reshape(1, -1))[0]\n",
    "\n",
    "for index in range(adv_samples):\n",
    "    clear_output(wait=True)\n",
    "    print('Claculating adv classification: ', index)\n",
    "    for layer in range(len(classifiers)):\n",
    "        adv_tags[index - test_samples, layer] = classifiers[layer].predict(adv_act_vectors[layer][index].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log likelihood of the switching sequence of both normal and adversarial examples\n",
    "(switch_prob, adv_switch_prob, log_probs, adv_log_probs) = plot_log_likelihood(tags, adv_tags, test_samples, adv_samples, start_layer = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the a-priori class switching probability for both normal and adversarial examples\n",
    "plot_apriori_switch_prob(switch_prob, adv_switch_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare correctly classified test instances with all test instances\n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "mask = y_pred == y_test_val\n",
    "\n",
    "x_test_filtered = x_test[0:test_samples][mask[0:test_samples]]\n",
    "x_adv_filtered = x_test[test_samples:test_samples + adv_samples][mask[test_samples:test_samples + adv_samples]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log likelihood of the switching sequence of both normal and adversarial examples\n",
    "filtered_tags = tags[mask[0:test_samples]]\n",
    "filtered_adv_tags = adv_tags[mask[test_samples:test_samples + adv_samples]]\n",
    "(switch_prob, adv_switch_prob, filtered_log_probs, filtered_adv_log_probs) = plot_log_likelihood(filtered_tags, \n",
    "                                                                                     filtered_adv_tags, \n",
    "                                                                                     len(filtered_tags), \n",
    "                                                                                     len(filtered_adv_tags),\n",
    "                                                                                     start_layer = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the a-priori class switching probability for both normal and adversarial examples\n",
    "plot_apriori_switch_prob(switch_prob, adv_switch_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered AUC curve\n",
    "samples = -1 * np.concatenate((filtered_log_probs, filtered_adv_log_probs))\n",
    "labels = np.concatenate((np.array([0,]*len(x_test_filtered)), np.array([1,]*len(x_adv_filtered))))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, samples, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "plt.figure(figsize = (5, 5))\n",
    "lw = 1\n",
    "plt.plot(fpr, tpr, color='green', lw=lw, label='Correct (AUC=%.2f)'%auc)\n",
    "\n",
    "# Add the non-filtered AUC curve\n",
    "samples = -1 * np.concatenate((log_probs, adv_log_probs))\n",
    "labels = np.concatenate((np.array([0,]*test_samples), np.array([1,]*adv_samples)))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels, samples, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='navy', lw=lw, label='(AUC=%.2f)'%auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.yticks(np.arange(0, 1.05, 0.05))\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "#plt.title('Receiver Operating Characteristic Curve')\n",
    "\n",
    "plt.show()\n",
    "print('AUC: %.2f'%auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
